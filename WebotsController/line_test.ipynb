{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from controller import Robot\n",
    "\n",
    "from WebotsEnvironment import WebotsEnvironment\n",
    "from WebotsGymEnv import WebotsGymEnv\n",
    "\n",
    "env = WebotsEnvironment()\n",
    "    \n",
    "obs = env.reset()[0]\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    src = np.float32([(0, height),\n",
    "                        ((width * 0.25) + 50, height * 0.50),\n",
    "                        ((width * 0.75) - 50, height * 0.50),\n",
    "                        (width, height),])    # top-right\n",
    "    \n",
    "    dst = np.float32([(0, height),\n",
    "                        (100, 100),\n",
    "                        (width - 100, 100),\n",
    "                        (width, height)])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # Apply the perspective transformation\n",
    "    warped = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "    return warped, M, M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pipeline(image, center_margin = 50):\n",
    "    \"\"\"\n",
    "    An image processing pipeline which will output\n",
    "    an image with the lane lines annotated.\n",
    "    \"\"\"\n",
    "    \n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    region_of_interest_vertices = [\n",
    "        (0, height),\n",
    "        (width * 0.25, height * 0.50),\n",
    "        (width * 0.75, height * 0.50),\n",
    "        (width, height),\n",
    "    ]\n",
    "\n",
    "    cropped_image = region_of_interest(\n",
    "        image,\n",
    "        np.array(\n",
    "            [region_of_interest_vertices],\n",
    "            np.int32\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    upper_yellow = np.array([215, 220, 237])\n",
    "    lower_yellow = np.array([80, 80, 208])\n",
    "\n",
    "    mask = cv2.inRange(cropped_image, lower_yellow, upper_yellow)\n",
    "    masked = cv2.bitwise_and(image, image , mask=mask)\n",
    "\n",
    "    gray_image = cv2.cvtColor(masked, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    warped, M, M_inv = perspective_transform(gray_image)\n",
    "    cannyed_image = cv2.Canny(warped, 850, 250, apertureSize=3)\n",
    "    \n",
    "    lines = cv2.HoughLinesP(cannyed_image, rho=2.5, theta=np.pi/180, threshold=15, minLineLength=20, maxLineGap=15)\n",
    "        \n",
    "    left_points = []\n",
    "    right_points = []\n",
    "\n",
    "    center = cannyed_image.shape[1] // 2\n",
    "\n",
    "    left_weight = 0\n",
    "    right_weight = 0\n",
    "\n",
    "    def calc_weight(x):\n",
    "        return abs(x - center)\n",
    "    \n",
    "    if lines is None:\n",
    "        return left_weight,right_weight,gray_image,0,cropped_image,cannyed_image\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "\n",
    "            if abs(x1 - x2) > 5 and abs(x1 - x2) < 10:\n",
    "                continue  # Skip vertical lines to avoid division by zero\n",
    "            \n",
    "            if x1 < center - center_margin :  # Left line\n",
    "                left_points.append((x1, y1))\n",
    "                left_weight += calc_weight(x1)\n",
    "            if x2 < center - center_margin :  # Left line\n",
    "                left_points.append((x2, y2))\n",
    "                left_weight += calc_weight(x2)\n",
    "            \n",
    "            if x1 > center + center_margin :  # Left line\n",
    "                right_points.append((x1, y1))\n",
    "                right_weight += calc_weight(x1)\n",
    "                \n",
    "            if x2 > center + center_margin :  # Left line\n",
    "                right_points.append((x2, y2))\n",
    "                right_weight += calc_weight(x2)\n",
    "                \n",
    "    if len(right_points) > 0:\n",
    "        right_weight = right_weight / len(right_points)\n",
    "\n",
    "    if len(left_points) > 0:\n",
    "        left_weight = left_weight / len(left_points)\n",
    "         \n",
    "    return left_weight,right_weight,gray_image,len(lines),cropped_image,cannyed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_steering_angle(image_width, left_weight, right_weight):\n",
    "    final_weight = right_weight - left_weight\n",
    "\n",
    "    diff = image_width / 2\n",
    "    angle = final_weight / diff\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radian = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heading_vector():\n",
    "        \n",
    "    compass = np.array(env.compass.getValues()[0:2], dtype=np.float16)\n",
    "    # Rotate the vector\n",
    "    # rotated_vector = [-compass[1] , -compass[0]]\n",
    "\n",
    "    return compass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -0.91, dist: 0.29, angle: -1.20, done: False\r"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "env.step(action=[1,radian],max_steps=1000)\n",
    "camera = env.camera\n",
    "\n",
    "pointer = camera.getImage()\n",
    "        \n",
    "image_array = np.frombuffer(pointer, dtype=np.uint8)\n",
    "\n",
    "# Reshape the array to the shape (height, width, 4) assuming the image has 4 channels (RGBA)\n",
    "img = image_array.reshape((camera.height, camera.width, 4))\n",
    "rgb_array = img[:, :, :3]\n",
    "\n",
    "cv2_img = rgb_array\n",
    "\n",
    "left_weight,right_weight,gray_image,lines,cropped_image,cannyed_image = pipeline(cv2_img, center_margin=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_steering_angle(gray_image.shape[1],left_weight,right_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00e+00  2.56e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.028575993445373444"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_position = env.previous_pos\n",
    "current_position = np.array(env.gps.getValues()[0:2])\n",
    "compass_heading = get_heading_vector()\n",
    "print(compass_heading)\n",
    "\n",
    "# Calculate the displacement vector\n",
    "displacement = current_position - previous_position\n",
    "\n",
    "# Normalize the compass heading vector to get the forward direction\n",
    "forward_direction = compass_heading / np.linalg.norm(compass_heading)\n",
    "\n",
    "# Extend the forward direction to 3D (XY plane, Z=0)\n",
    "forward_direction_3d = np.array([forward_direction[0], forward_direction[1]])\n",
    "\n",
    "# Project the displacement vector onto the forward direction\n",
    "forward_distance = np.dot(displacement, forward_direction_3d)\n",
    "forward_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_weight,right_weight,lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = cv2_img.shape[:2]\n",
    "y_eval = height  # Evaluate at the bottom of the image\n",
    "\n",
    "if left_fit is not None and right_fit is not None:\n",
    "    left_x = np.polyval(left_fit, y_eval)\n",
    "    right_x = np.polyval(right_fit, y_eval)\n",
    "    lane_center = (left_x + right_x) / 2\n",
    "elif left_fit is not None:\n",
    "    lane_center = np.polyval(left_fit, y_eval)\n",
    "elif right_fit is not None:\n",
    "    lane_center = np.polyval(right_fit, y_eval)\n",
    "else:\n",
    "    lane_center = width / 2\n",
    "\n",
    "# Calculate angle in radians\n",
    "angle = np.arctan((lane_center - width / 2) / y_eval)\n",
    "\n",
    "# Convert angle to degrees\n",
    "angle_degrees = np.degrees(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_angle = calculate_steering_angle(cv2_img.shape[:2], left_fit if left_r_squared >= right_r_squared else None, \n",
    "                                                        right_fit if right_r_squared >= left_r_squared else None)\n",
    "radian = steering_angle * (np.pi/180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
